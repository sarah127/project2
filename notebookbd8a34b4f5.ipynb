{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10201008,
          "sourceType": "datasetVersion",
          "datasetId": 6303717
        }
      ],
      "dockerImageVersionId": 30804,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebookbd8a34b4f5",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarah127/project2/blob/master/notebookbd8a34b4f5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "sarahali_milddementedrgb_pro256_fin_path = kagglehub.dataset_download('sarahali/milddementedrgb-pro256-fin')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "CSgsHUeC2_7x"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dqBsftsS3EjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Xbec8Gva2_78"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import tensorflow.compat.v1 as tf\n",
        "import skimage\n",
        "import skimage.io"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T16:50:20.545292Z",
          "iopub.execute_input": "2025-01-18T16:50:20.545542Z",
          "iopub.status.idle": "2025-01-18T16:50:35.539954Z",
          "shell.execute_reply.started": "2025-01-18T16:50:20.545516Z",
          "shell.execute_reply": "2025-01-18T16:50:35.539023Z"
        },
        "id": "z7osKKLs2_7_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Current_path='/kaggle/working'\n",
        "sub2=[]\n",
        "lastfolder=[]\n",
        "MainParent=os.path.join(Current_path,'AlzheimerDataset')#/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset #AlzheimerDataset\n",
        "for subfolder1 in tqdm(os.listdir('/kaggle/input/alzheimer-mri-4-classes-dataset/Alzheimer_MRI_4_classes_dataset')):\n",
        "    subfolder1 = os.path.join('/kaggle/input/alzheimer-mri-4-classes-dataset/Alzheimer_MRI_4_classes_dataset', subfolder1)\n",
        "    subfolder2=os.path.join(MainParent,os.path.basename(subfolder1))\n",
        "    if not os.path.exists(subfolder2):\n",
        "            os.makedirs(subfolder2)\n",
        "    sub2.append(subfolder2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "x6sCLJmu2_8D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "for subfolder in tqdm(os.listdir('/kaggle/input/alzheimer-mri-4-classes-dataset/Alzheimer_MRI_4_classes_dataset')):\n",
        "    subfolder_path = os.path.join('/kaggle/input/alzheimer-mri-4-classes-dataset/Alzheimer_MRI_4_classes_dataset', subfolder)\n",
        "    for i in range(len(sub2)):\n",
        "        if os.path.basename(subfolder_path)==os.path.basename(sub2[i]):\n",
        "            for image_filename in os.listdir(subfolder_path):\n",
        "                if image_filename.endswith(\".jpg\") or image_filename.endswith(\".png\") or image_filename.endswith(\".JPG\"):\n",
        "                    ##image = Image.open(os.path.join(subfolder_path,image_filename))\n",
        "                    ##resized_image = image.resize((512, 512))\n",
        "                    ##image_rgb = resized_image.convert(\"RGB\")\n",
        "                    ##image_rgb.save(os.path.join(sub2[i],image_filename))\n",
        "                    image = cv2.imread(os.path.join(subfolder_path,image_filename), cv2.IMREAD_GRAYSCALE)\n",
        "                    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                    image_normalized = cv2.normalize(image_rgb, None, 0, 1, cv2.NORM_MINMAX)  # [0,1] range# For GANs, [-1, 1] range is often preferred\n",
        "                    image_normalized = 2 * image_normalized - 1  # Convert from [0,1] to [-1,1]2. Resizing\n",
        "                    resized_image = cv2.resize(image_normalized, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
        "                    #$$augmented_image = cv2.rotate(resized_image, cv2.ROTATE_90_CLOCKWISE)  # Example rotation\n",
        "                    #$$flipped_image = cv2.flip(augmented_image, 1)  # Horizontal flip\n",
        "                    #image_with_channel = np.expand_dims(image_resized, axis=-1)\n",
        "                    # Scale the pixel values to the range [0, 1]\n",
        "                    #normalized_image = resized_image / 255.0\n",
        "                    # Add the channel dimension to make the shape (256, 256, 1)\n",
        "                    # Apply histogram equalization to improve contrast\n",
        "                    #equalized_image = cv2.equalizeHist(denoised_image.astype(np.uint8))\n",
        "                    #image_with_channel = np.expand_dims(normalized_image, axis=-1)\n",
        "                    cv2.imwrite(os.path.join(sub2[i],image_filename), resized_image)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Dz6gZWic2_8F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "# Get directory name\n",
        "mydir = '/kaggle/working/training-runs'\n",
        "\n",
        "# Try to remove the tree; if it fails, throw an error using try...except.\n",
        "try:\n",
        "    shutil.rmtree(mydir)\n",
        "except OSError as e:\n",
        "    print(\"Error: %s - %s.\" % (e.filename, e.strerror))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T16:49:16.320561Z",
          "iopub.execute_input": "2025-01-18T16:49:16.321571Z",
          "iopub.status.idle": "2025-01-18T16:49:16.32743Z",
          "shell.execute_reply.started": "2025-01-18T16:49:16.321532Z",
          "shell.execute_reply": "2025-01-18T16:49:16.326548Z"
        },
        "id": "wzonx7bH2_8H"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sarah127/Diffusion-GAN.git"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-14T17:46:39.055385Z",
          "iopub.execute_input": "2024-12-14T17:46:39.056426Z",
          "iopub.status.idle": "2024-12-14T17:46:40.990064Z",
          "shell.execute_reply.started": "2024-12-14T17:46:39.056387Z",
          "shell.execute_reply": "2024-12-14T17:46:40.989209Z"
        },
        "id": "FIpjnSrf2_8I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /kaggle/working/Diffusion-GAN/diffusion-projected-gan"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T16:51:13.546085Z",
          "iopub.execute_input": "2025-01-18T16:51:13.546731Z",
          "iopub.status.idle": "2025-01-18T16:51:13.552873Z",
          "shell.execute_reply.started": "2025-01-18T16:51:13.546697Z",
          "shell.execute_reply": "2025-01-18T16:51:13.551928Z"
        },
        "id": "xNcNOzkn2_8N",
        "outputId": "27ec8d8c-6138-4e6b-e3f0-9366bf09e70d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/working/Diffusion-GAN/diffusion-projected-gan\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install timm==0.5.4\n",
        "!pip install ftfy\n",
        "!pip install Ninja\n",
        "!pip install setuptools==59.5.0\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T16:51:17.024681Z",
          "iopub.execute_input": "2025-01-18T16:51:17.025472Z",
          "iopub.status.idle": "2025-01-18T16:52:06.465341Z",
          "shell.execute_reply.started": "2025-01-18T16:51:17.025439Z",
          "shell.execute_reply": "2025-01-18T16:52:06.464116Z"
        },
        "id": "QFCMpK-W2_8S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import click\n",
        "import re\n",
        "import json\n",
        "import tempfile\n",
        "import torch\n",
        "import dnnlib\n",
        "import train\n",
        "from training import training_loop\n",
        "from metrics import metric_main\n",
        "from torch_utils import training_stats\n",
        "from torch_utils import custom_ops\n",
        "import legacy"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T16:52:29.659741Z",
          "iopub.execute_input": "2025-01-18T16:52:29.66009Z",
          "iopub.status.idle": "2025-01-18T16:52:33.455688Z",
          "shell.execute_reply.started": "2025-01-18T16:52:29.660061Z",
          "shell.execute_reply": "2025-01-18T16:52:33.454947Z"
        },
        "id": "1ZxMo7MK2_8U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"2\"\n",
        "!set CUDA_LAUNCH_BLOCKING = 1\n",
        "os.environ['TORCH_CUDA_ARCH_LIST']='7.5'\n",
        "!export CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T16:52:38.162269Z",
          "iopub.execute_input": "2025-01-18T16:52:38.162628Z",
          "iopub.status.idle": "2025-01-18T16:52:40.19444Z",
          "shell.execute_reply.started": "2025-01-18T16:52:38.162595Z",
          "shell.execute_reply": "2025-01-18T16:52:40.19336Z"
        },
        "id": "6LeZiEfb2_8V",
        "outputId": "ee468476-a9c3-4227-d299-6c9d1a8e9dcb"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T16:52:48.131734Z",
          "iopub.execute_input": "2025-01-18T16:52:48.132164Z",
          "iopub.status.idle": "2025-01-18T16:52:48.13629Z",
          "shell.execute_reply.started": "2025-01-18T16:52:48.132133Z",
          "shell.execute_reply": "2025-01-18T16:52:48.135308Z"
        },
        "id": "1hUCLD0J2_8W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!python /kaggle/working/Diffusion-GAN/diffusion-projected-gan/train.py  --outdir=training-runs  --data='/kaggle/input/milddementedrgb-pro256-fin' --gpus=1 --cfg='fastgan' --kimg=3670 --target=0.45 --d_pos='first' --noise_sd=0.5  --batch=16    --resume=\"https://huggingface.co/zhendongw/diffusion-gan/resolve/main/checkpoints/diffusion-projectedgan-lsun-bedroom.pkl\" --snap=5 --seed=0 --restart_every=9999999 --cbase=32768  --cmax=512  --dlr=0.002 --metrics=None"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T16:17:47.441701Z",
          "iopub.execute_input": "2025-01-18T16:17:47.442045Z",
          "iopub.status.idle": "2025-01-18T16:18:06.365113Z",
          "shell.execute_reply.started": "2025-01-18T16:17:47.442013Z",
          "shell.execute_reply": "2025-01-18T16:18:06.364072Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Yky0PTgo2_8X",
        "outputId": "b130ce62-d5b7-4f50-cde9-e2b8ef3a0b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nTraining options:\n{\n  \"G_kwargs\": {\n    \"class_name\": \"pg_modules.networks_fastgan.Generator\",\n    \"cond\": false,\n    \"synthesis_kwargs\": {\n      \"lite\": false\n    }\n  },\n  \"G_opt_kwargs\": {\n    \"class_name\": \"torch.optim.Adam\",\n    \"betas\": [\n      0,\n      0.99\n    ],\n    \"eps\": 1e-08,\n    \"lr\": 0.0002\n  },\n  \"D_opt_kwargs\": {\n    \"class_name\": \"torch.optim.Adam\",\n    \"betas\": [\n      0,\n      0.99\n    ],\n    \"eps\": 1e-08,\n    \"lr\": 0.0002\n  },\n  \"data_loader_kwargs\": {\n    \"pin_memory\": true,\n    \"prefetch_factor\": 2,\n    \"num_workers\": 3\n  },\n  \"target\": 0.45,\n  \"ada_kimg\": 100,\n  \"training_set_kwargs\": {\n    \"class_name\": \"training.dataset.ImageFolderDataset\",\n    \"path\": \"/kaggle/input/milddementedrgb-pro256-fin\",\n    \"use_labels\": false,\n    \"max_size\": 896,\n    \"xflip\": true,\n    \"resolution\": 256,\n    \"random_seed\": 0\n  },\n  \"num_gpus\": 1,\n  \"batch_size\": 16,\n  \"batch_gpu\": 16,\n  \"metrics\": [],\n  \"total_kimg\": 3670,\n  \"kimg_per_tick\": 4,\n  \"image_snapshot_ticks\": 5,\n  \"network_snapshot_ticks\": 5,\n  \"random_seed\": 0,\n  \"ema_kimg\": 5.0,\n  \"resume_pkl\": \"https://huggingface.co/zhendongw/diffusion-gan/resolve/main/checkpoints/diffusion-projectedgan-lsun-bedroom.pkl\",\n  \"ema_rampup\": null,\n  \"restart_every\": 9999999,\n  \"loss_kwargs\": {\n    \"class_name\": \"training.loss.ProjectedGANLoss\"\n  },\n  \"D_kwargs\": {\n    \"class_name\": \"pg_modules.discriminator.ProjectedDiscriminator\",\n    \"diffaug\": true,\n    \"interp224\": false,\n    \"backbone_kwargs\": {\n      \"d_pos\": \"first\",\n      \"noise_sd\": 0.5,\n      \"cout\": 64,\n      \"expand\": true,\n      \"proj_type\": 2,\n      \"num_discs\": 4,\n      \"separable\": false,\n      \"cond\": false\n    }\n  },\n  \"run_dir\": \"training-runs/00000-fastgan-milddementedrgb-pro256-fin-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100\"\n}\n\nOutput directory:    training-runs/00000-fastgan-milddementedrgb-pro256-fin-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100\nNumber of GPUs:      1\nBatch size:          16 images\nTraining duration:   3670 kimg\nDataset path:        /kaggle/input/milddementedrgb-pro256-fin\nDataset size:        896 images\nDataset resolution:  256\nDataset labels:      False\nDataset x-flips:     True\n\nCreating output directory...\nLaunching processes...\nLoading training set...\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/sampler.py:65: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n\nNum images:  1792\nImage shape: [3, 256, 256]\nLabel shape: [0]\n\nConstructing networks...\nDownloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_lite0-0aa007d2.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_lite0-0aa007d2.pth\nResuming from \"training-runs/00000-fastgan-milddementedrgb-pro256-fin-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl\"\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\nTraceback (most recent call last):\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/train.py\", line 281, in <module>\n    main() # pylint: disable=no-value-for-parameter\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/train.py\", line 267, in main\n    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/train.py\", line 101, in launch_training\n    subprocess_fn(rank=0, c=c, temp_dir=temp_dir)\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/train.py\", line 47, in subprocess_fn\n    training_loop.training_loop(rank=rank, **c)\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training/training_loop.py\", line 176, in training_loop\n    resume_data = legacy.load_network_pkl(f)\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py\", line 24, in load_network_pkl\n    data = _LegacyUnpickler(f).load()\n_pickle.UnpicklingError: pickle data was truncated\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!python /kaggle/working/Diffusion-GAN/diffusion-projected-gan/calc_metrics.py  --metrics=fid50k_full --data='/kaggle/input/milddementedrgb-pro256-fin' --mirror=1   --network='/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training-runs/00000-fastgan-milddementedrgb-pro256-fin-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T16:57:13.871517Z",
          "iopub.execute_input": "2025-01-18T16:57:13.87192Z",
          "iopub.status.idle": "2025-01-18T16:57:23.202042Z",
          "shell.execute_reply.started": "2025-01-18T16:57:13.871889Z",
          "shell.execute_reply": "2025-01-18T16:57:23.201145Z"
        },
        "id": "3-9ujlGh2_8Y",
        "outputId": "2e387f46-82e1-4744-c3fc-cf54004fe115"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading network from \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training-runs/00000-fastgan-milddementedrgb-pro256-fin-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl\"...\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\nTraceback (most recent call last):\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/calc_metrics.py\", line 186, in <module>\n    calc_metrics() # pylint: disable=no-value-for-parameter\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/click/decorators.py\", line 33, in new_func\n    return f(get_current_context(), *args, **kwargs)\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/calc_metrics.py\", line 144, in calc_metrics\n    network_dict = legacy.load_network_pkl(f)\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py\", line 24, in load_network_pkl\n    data = _LegacyUnpickler(f).load()\n_pickle.UnpicklingError: pickle data was truncated\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}